# detection-of-fake-accounts

# Курсовой проект: Обнаружение ложных аккаунтов в социальных сетях с помощью моделей машинного обучения

## Описание проекта

Данный проект представляет собой курсовую работу, выполненную студенткой группы Факультета информационных технологий и анализа больших данных Финансового университета при Правительстве Российской Федерации. Цель работы — разработка и сравнительный анализ моделей машинного обучения для классификации пользователей социальных сетей (человек или бот) на основе обрезанного набора данных TwiBot-22, содержащего 10 000 аккаунтов (5 000 людей и 5 000 ботов). Исследование охватывает методы обработки текстовых, числовых и графовых данных, включая глубокое обучение и бустинг, с акцентом на обеспечение безопасности цифровой среды.

## Автор

- **Имя:** Торочкина Яна Александровна  
- **Дата создания:** Май 2025

## Используемые технологии и инструменты

- **Язык программирования:** Python 3.9  
- **Библиотеки:**  
  - PyTorch (для глубоких нейронных сетей)  
  - torch_geometric (для работы с графовыми данными)  
  - Transformers (для использования DistilBERT)  
  - XGBoost (для ансамблевых моделей)  
  - scikit-learn (для предобработки и оценки метрик)  
  - NLTK и spaCy (для обработки текстов)  
  - NetworkX (для анализа графов)  
  - NumPy и Pandas (для работы с данными)  
- **Среда разработки:** Jupyter Notebook  
- **Оборудование:** Рекомендуется GPU (например, NVIDIA GTX 1080) для ускорения обучения

## Структура проекта

- **`main.ipynb`:** Основной Jupyter Notebook, содержащий код для предобработки данных, обучения моделей (MLP, Final MLP, LSTM, Transformer, GAT, XGBoost) и анализа результатов.  
- **`results/`:** Папка с сохраненными результатами, включая графики потерь, ROC-кривые, матрицы ошибок и таблицу метрик.  
- **`README.md`:** Настоящий файл с описанием проекта.  

## Установка и запуск

### Требования
1. Установите Python 3.9 или выше.
2. Установите необходимые библиотеки, выполнив следующую команду в терминале:
   ```
   pip install torch torchvision torchaudio torch-geometric transformers xgboost scikit-learn nltk spacy networkx numpy pandas matplotlib seaborn
   ```
   Убедитесь, что версии библиотек совместимы (например, PyTorch 1.10.0, Transformers 4.18.0).

### Подготовка данных
1. Убедитесь, что набор данных TwiBot-22 (обрезанная версия с 10 000 аккаунтов) доступен. Данные должны включать текстовые описания профилей, числовые метрики (подписчики, твиты и т.д.) и графовые связи.  
2. Загрузите данные вручную в `main.ipynb` (например, через pandas.read_csv или другие методы, указанные в коде).

### Запуск проекта
1. Откройте Jupyter Notebook, запустив команду:
   ```
   jupyter notebook
   ```
2. Откройте файл `main.ipynb` и выполните ячейки в следующем порядке:  
   - Предобработка данных (загрузка и очистка).  
   - Обучение моделей (MLP, Final MLP, LSTM, Transformer, GAT, XGBoost).  
   - Анализ результатов и визуализация (графики сохраняются в `results/`).  
3. Результаты автоматически сохраняются в папке `results/` в формате PNG (графики) и CSV (метрики).

## Результаты

Проект включает сравнительный анализ шести моделей:  
- **MLP:** F1-score 0.765335, ROC-AUC 0.853128.  
- **Final MLP:** F1-score 0.758596, ROC-AUC 0.853354.  
- **LSTM:** F1-score 0.757427, ROC-AUC 0.854927.  
- **Transformer:** F1-score 0.749115, ROC-AUC 0.810099.  
- **GAT:** F1-score 0.758421, ROC-AUC 0.838619.  
- **XGBoost:** F1-score 0.759897, ROC-AUC 0.832583.  

**MLP** и **Final MLP** выделяются как лучшие модели благодаря высокой точности, устойчивости к переобучению и оптимальному времени обучения. Подробные результаты доступны в папке `results/`.

## Ограничения
- Использован обрезанный набор данных (10 000 аккаунтов), что может ограничивать обобщающую способность моделей.  
- Отсутствие автоматизированной загрузки данных требует ручного вмешательства.  
- Ограниченные ресурсы для настройки гиперпараметров могут влиять на производительность сложных моделей.

## Будущие улучшения
- Интеграция полного набора данных TwiBot-22 для повышения точности.  
- Автоматизация загрузки и предобработки данных.  
- Оптимизация гиперпараметров (`hidden_dim`, `learning_rate`, `batch_size`).  
- Добавление аугментации текстов и мультимодальных данных.


---

Дата последнего обновления: 17:06 CEST, 21 мая 2025.
